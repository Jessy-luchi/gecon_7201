---
title: |
  |Name : Oluchi Jessica Onyekwere
  |Student ID: 3192227
  |
  | ECON 7201
  | Applied Econometrics
subtitle: "Assignment 2"
format: 
  pdf:
    include-in-header: 
      text: |
        \usepackage{fancyhdr}
        \fancypagestyle{style2}{
        \fancyhf{}
        \fancyhead[R]{Assignment 1}
        \fancyhead[L]{ECON 3201}
        \fancyfoot[C]{\thepage}
        \renewcommand{\headrulewidth}{1pt}
        }
        \pagestyle{style2}
execute: 
  eval: true
  echo: true
---

```{r}
#| label: setup 
#| include: FALSE

#install.packages("tikzDevice")
# Load the tikzDevice library
library(tikzDevice)

# Set the default graphics device to tikz for the entire document
knitr::opts_chunk$set(dev = 'tikz', fig.width = 6, fig.height = 4)

set.seed(42)
```

\vspace{-1in}

## Due Date

**Sunday October 5, 2025** at 11:59 PM

## Directions

Answer all questions. Submit both a PDF and Quarto file to the nexus assignment portal.

# Git and GitHub

1.  

    (a) Create a new R project in your **econ_3201** directory called **assignment_2**.
    (b) Download the assignment PDF and Quarto file the **assignment_2** folder.
    (c) Commit and push the changes to your **econ_3201** repository on [GitHub.com](GitHub.com).

# LaTeX

Matrices are created in LaTeX using the `\begin{bmatrix}...\end{bmatrix}` command. To separate entries along the same row, use `&`. To end a line, use `\\`. To make vertical elipses ($\vdots$), use `\vdots`. Practice writing the following matrices and vectors in LaTeX. Write the following matrices in LaTeX.

2.  
(a)
$$

$X'X=
\begin{bmatrix}
n & \sum^n_{i=1} x_{1i} & \sum^n_{i=1} x_{2i}\\
\sum^n_{i=1} x_{1i} & \sum^n_{i=1} x^2_{1i} & \sum^n{i=1} x_{1i}x_{2i}\\
\sum^n_{i=1} x_{2i} & \sum^n_{i=1} x_{1i}x{2i} & \sum^n_{1} x^2_{2i}\\
\end{bmatrix}$

(b)
$\Omega =
\begin{bmatrix}
\sigma^2_1 & 0 & 0 & 0\\
0 & \sigma^2_2 & 0 & 0\\
0 & 0 & \sigma^2_3 & 0\\
0 & 0 & 0 & \sigma^2_4
\end{bmatrix}$


# R

3.  In this question we compare standard errors based on (incorrect) asymptotic assumptions with those based on alternate (appropriate) estimator (White). Consider one sample drawn from the following data generating process (DGP) which we will simulate in `R`:

```{r}
set.seed(123)
n <- 25
x <- rnorm(n,mean=0.0,sd=1.0)
beta0 <- 1
beta1 <- 0
## x is irrelevant in this model, the data generating process is as follows:
dgp <- beta0 + beta1*x
## The residual is heteroskedastic by construction
e <- x^2*rnorm(n,mean=0.0,sd=1.0)
y <- dgp + e
```

> (a) Compute the OLS estimator of $\beta_2$ and its standard error using the `lm()` command in `R` for the model $y_i=\beta_1+\beta_2 x_i+\epsilon_i$ based on the DGP given above.

```{r}
lm(y ~ x)
```

> (b) Next, compute the standard error of $\hat\beta_2$ by computing $\hat\sigma^2(X'X)^{-1}$ in `R` using matrix commands, and verify that the two standard error estimates are identical.

```{r}
X <- cbind(1,x)
beta_hat2 <- solve(t(X)%*% X) %*% t(X) %*% y 

cbind(matrix =as.numeric(beta_hat2), 
      lm = coef(lm(y~x)))

```

> (c) Compute White's heteroskedasticity consistent covariance matrix estimator using matrices in R and report the White estimator of the standard error of $\hat\beta_2$. Compare this with that from 3 (a) above.

```{r}
resid <- y-X%*% beta_hat2

white_beta_hat2 <- matrix(0,
                 nrow = 2,
                 ncol = 2)
for(i in 1:n) {
  white_X <- X[i, , drop=FALSE]
  white_beta_hat2 <- white_beta_hat2 + as.numeric(resid[i]^2) * t(white_X) %*% white_X
}

white_Resid <- solve(t(X) %*% X)
white_Result <- white_Resid %*%  white_beta_hat2 %*% white_Resid

SE_white_beta_hat2 <- sqrt(white_Result[2,2])

beta_hat2


```

```{r}
SE_white_beta_hat2
```

Â 

4.  Let $\hat{\theta}$ be an estimator for the population parameter $\theta$. $\hat{\theta}$ is said to be unbiased if $E(\hat\theta)=\theta$. That is, if the mean of the sampling distribution of $\hat{\theta}$ is equal to the true population value.\
    \
    Consider the model $$y_i=\beta_0+\beta_1x_{1,i}-\beta_2x_{2,i}+\epsilon_i.$$ Lets provide empirical evidence that the ordinary least squares estimators $\hat\beta_0$, $\hat\beta_1$, and $\hat\beta_2$ are unbiased estimators of $\beta_0$, $\beta_1$, $\beta_2$, respectively, using R.
    (a) Set the seed to 1, i.e., `set.seed(1)`.

```{r}
set.seed(1)
```

```         
(b) Set the number of observations $n=100$
```

```{r}
n <- 100
```

```         
(c) Generate the following model $$y_i=2+3.5x_{1,i}-9.2x_{2,i}+\epsilon_i,$$ where $x_1\sim N(3,6)$, $x_2\sim N(2,4)$, and $\epsilon\sim N(0,100)$. To create a normally distributed variable, use the `rnorm(n, mean, sd)` command in R.
```

```{r}
x1 <- rnorm(n, mean=3, sd=6)
x2 <- rnorm(n, mean=2, sd=4)
epsilon <- rnorm(n,mean=0, sd=100)
y <- 2 + 3.5 * x1 -9.2 * x2 + epsilon
model <- lm(y ~ x1 + x2)
summary(model)

```

```         
(d) Estimate the model coefficients using the `lm()` command. (Search `?lm()` in the console for more info).
```

```{r}
lm(y~x1 + x2) $coefficient
```

```         
(e) Using a `for()` loop, replicate the model above $M=1000$ times and save the coefficient estimates from each iteration. 
```

```{r}
set.seed(1)
n = 100
M = 1000

coef_estimates <- matrix(0, nrow=M, ncol=3)
colnames(coef_estimates) <-c("intercept","x1_coef","x2_coef" )

for(i in 1:M){
x1 <- rnorm(n, mean = 3, sd = 6)
x2 <- rnorm(n, mean = 2, sd = 4)
epsilon <- rnorm(n, mean = 0, sd=100)
y <-  2 + 3.5 * x1 -9.2 * x2 + epsilon

model <- lm(y ~ x1 + x2)
coef_estimates[i,] <-coef(model)

}

summary(model)

```

```{r}
lm(y~x1+x2)$coefficients
```

```         
(f) Using `hist()`, plot the sampling distributions of the coefficient estimates, $\beta_1$ and $\beta_2$. 
```

```{r}
#| eval: true
#| fig-cap: "Sampling Distribution from 1000 iterations for x1_coef"
#| label: fig-1


hist(coef_estimates[, "x1_coef"],
     main = "Sampling Distribution from 1000 iterations",
     xlab = x1,
     col = "lightblue",)
```


```{r}
#| eval: true
#| fig-cap: "Sampling Distribution from 1000 iterations for x2_coef"
#| label: fig-2

hist(coef_estimates[, "x2_coef"],
     main = "Sampling Distribution from 1000 iterations",
     xlab = x2,
     col = "pink")

```

(g) Add a vertical line to each figure at the mean of the respective variable. Search `?abline()` in your console.


```{r}
#| eval: true
#| fig-cap: "Sampling Distribution from 1000 iterations with the vertical line drawn at the mean of each respective variable for x1_coef"
#| label: fig-3

hist(coef_estimates[, "x1_coef"],
     main =  "Sampling Distribution from 1000 iterations",
     xlab = x1,
     col = "lightblue",)


abline(v = mean(coef_estimates[,"x1_coef"]),
       col="black",
       lwd=2,
       lty=2)
```

```{r}
#| eval: true
#| fig-cap: "Sampling Distribution from 1000 iterations with the vertical line drawn at the mean of each respective variable for x2_coef"
#| label: fig-4

hist(coef_estimates[, "x2_coef"],
     main = "Sampling Distribution from 1000 iterations",
     xlab = x2,
     col = "pink")

abline(v=mean(coef_estimates[, "x2_coef"]),
       col="purple",
       lwd=2,
       lty=2)
```
```         
```
